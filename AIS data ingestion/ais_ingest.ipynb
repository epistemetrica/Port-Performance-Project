{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIS Data Ingestion \n",
    "\n",
    "Vessel locations data is ingested from the Automatic Identification System (AIS) data available from the federal [Marine Cadastre website](https://hub.marinecadastre.gov/pages/vesseltraffic), and is processed in the following steps:\n",
    "- read data from csv urls \n",
    "- drop unnessary columns\n",
    "- filter to only include cargo vessels\n",
    "- cast datatypes appropriately\n",
    "- append to a monthly file for storage\n",
    "- save monthly files to parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preliminaries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "#enable string cache for polars categoricals\n",
    "pl.enable_string_cache()\n",
    "#display settings\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init globals\n",
    "\n",
    "#dates\n",
    "years = pl.arange(2015,2025,eager=True)\n",
    "months = pl.arange(1,13,eager=True)\n",
    "days = pl.arange(1,32,eager=True)\n",
    "\n",
    "#vessel types\n",
    "cargo_types = pl.arange(70,80,eager=True)\n",
    "\n",
    "#monthly df\n",
    "month_df = pl.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through years\n",
    "for year in [2024]:\n",
    "    #loop through months\n",
    "    for month in months:\n",
    "        #loop through days\n",
    "        for day in days:\n",
    "            #load from url to pandas df\n",
    "            try:\n",
    "                day_df = (\n",
    "                    pd.read_csv(f'https://coast.noaa.gov/htdata/CMSP/AISDataHandler/{year}/AIS_{year}_{month:02d}_{day:02d}.zip')\n",
    "                )\n",
    "                print(f'Download complete for {year}_{month}_{day}.')\n",
    "            except:\n",
    "                print(f'Invalid URL for {year}_{month}_{day} - Date may be invalid or file may not exist.')\n",
    "                continue\n",
    "            #convert to polars ;)\n",
    "            day_df = pl.DataFrame(day_df)\n",
    "            #process data\n",
    "            day_df = (\n",
    "                day_df\n",
    "                #keep only cargo vessels\n",
    "                .filter(pl.col('VesselType').is_in(cargo_types))\n",
    "                #keep cols of interest\n",
    "                .select('MMSI', 'BaseDateTime','LAT', 'LON', 'SOG', 'COG', \n",
    "                        'Heading', 'VesselName', 'IMO')\n",
    "                #give pythonic names\n",
    "                .rename({\n",
    "                    'MMSI':'mmsi',\n",
    "                    'BaseDateTime':'time',\n",
    "                    'LAT':'lat',\n",
    "                    'LON':'lon',\n",
    "                    'SOG':'speed',\n",
    "                    'COG':'course',\n",
    "                    'Heading':'heading',\n",
    "                    'VesselName':'vessel_name',\n",
    "                    'IMO':'imo'\n",
    "                })\n",
    "                #clean cols\n",
    "                .with_columns(\n",
    "                    #strip IMO prefix and cast to int\n",
    "                    imo = pl.col('imo').str.strip_prefix('IMO').cast(pl.Int64),\n",
    "                    #clean course and heading \n",
    "                    course = pl.col('course').replace(360.0,None),\n",
    "                    heading = pl.col('heading').replace(511.0,None)\n",
    "                )\n",
    "                #cast\n",
    "                .cast({\n",
    "                    'time':pl.Datetime,\n",
    "                    'vessel_name':pl.Categorical\n",
    "                })\n",
    "            )\n",
    "            #concat and deduplicate\n",
    "            month_df = pl.concat([month_df,day_df], how='diagonal').unique()\n",
    "        #save monthly data\n",
    "        month_df.write_parquet(f'data/clean parquet/{year}_{month}.parquet')\n",
    "        print(f'{year}_{month} file saved to parquet.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wsu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
