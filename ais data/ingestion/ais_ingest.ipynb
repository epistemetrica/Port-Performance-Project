{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIS Data Ingestion \n",
    "\n",
    "Vessel locations data is ingested from the Automatic Identification System (AIS) data available from the federal [Marine Cadastre website](https://hub.marinecadastre.gov/pages/vesseltraffic), and is processed in the following steps:\n",
    "- read data from csv urls \n",
    "- drop unnessary columns\n",
    "- filter to only include cargo vessels\n",
    "- cast datatypes appropriately\n",
    "- append to a monthly file for storage\n",
    "- save monthly files to parquet\n",
    "\n",
    "Descriptions of each column of the raw data are available at the [AIS Data Dictionary](https://coast.noaa.gov/data/marinecadastre/ais/data-dictionary.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preliminaries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from datetime import datetime \n",
    "\n",
    "#enable string cache for polars categoricals\n",
    "pl.enable_string_cache()\n",
    "#display settings\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set variables\n",
    " \n",
    "#start and end dates (format yyyy_mm_dd)\n",
    "start_date = '2018_01_01'\n",
    "end_date = '2024_03_31'\n",
    "\n",
    "#vessel types - includes cargo and tanker types\n",
    "cargo_types = pl.arange(70,90,eager=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#injest data\n",
    "\n",
    "#init dates \n",
    "days = pl.date_range(datetime.strptime(start_date, '%Y_%m_%d'),\n",
    "                  datetime.strptime(end_date, '%Y_%m_%d'),\n",
    "                  eager=True)\n",
    "\n",
    "#loop through days in range\n",
    "for day in days:\n",
    "    #get year\n",
    "    year = day.year\n",
    "    #convert day to string\n",
    "    day = day.strftime('%Y_%m_%d')\n",
    "    #load from url to pandas df\n",
    "    try:\n",
    "        day_raw = (\n",
    "            pd.read_csv(\n",
    "                f'https://coast.noaa.gov/htdata/CMSP/AISDataHandler/{year}/AIS_{day}.zip',\n",
    "                low_memory=False\n",
    "            )\n",
    "        )\n",
    "        print(f'Download complete for {day}.')\n",
    "        try:\n",
    "            #convert to polars\n",
    "            day_df = pl.DataFrame(day_raw,infer_schema_length=0)\n",
    "            #process data\n",
    "            day_df = (\n",
    "                day_df\n",
    "                #keep only cargo vessels\n",
    "                .filter(pl.col('VesselType').is_in(cargo_types))\n",
    "                #keep cols of interest\n",
    "                .select('MMSI', 'BaseDateTime','LAT', 'LON', 'SOG', 'COG', \n",
    "                        'Heading', 'Status', 'VesselName', 'VesselType', 'IMO',\n",
    "                        'Length', 'Width', 'Draft','Cargo')\n",
    "                #give pythonic names\n",
    "                .rename({\n",
    "                    'MMSI':'mmsi',\n",
    "                    'BaseDateTime':'time',\n",
    "                    'LAT':'lat',\n",
    "                    'LON':'lon',\n",
    "                    'SOG':'speed',\n",
    "                    'COG':'course',\n",
    "                    'Heading':'heading',\n",
    "                    'Status':'status',\n",
    "                    'VesselName':'vessel_name',\n",
    "                    'VesselType':'vessel_type',\n",
    "                    'IMO':'imo',\n",
    "                    'Length':'length',\n",
    "                    'Width':'width',\n",
    "                    'Draft':'draft',\n",
    "                    'Cargo':'cargo'\n",
    "                })\n",
    "                #clean cols\n",
    "                .with_columns(\n",
    "                    #strip IMO prefix and cast to int\n",
    "                    imo = pl.col('imo').str.strip_prefix('IMO').cast(pl.Int64),\n",
    "                    #clean course and heading \n",
    "                    course = pl.col('course').replace(360.0,None),\n",
    "                    heading = pl.col('heading').replace(511.0,None)\n",
    "                )\n",
    "                #cast\n",
    "                .cast({\n",
    "                    'time':pl.Datetime,\n",
    "                    'vessel_name':pl.Categorical\n",
    "                })\n",
    "                #deduplicate\n",
    "                .unique()\n",
    "            )\n",
    "            #write to parquet\n",
    "            day_df.write_parquet(f'../data/ais_clean/ais_{day}.parquet')\n",
    "            print(f'{day} successfully processed and saved to parquet.')\n",
    "        except:\n",
    "            try:\n",
    "                day_raw.to_csv(f'../data/ais_processing_errors/ais_{day}.csv')\n",
    "                print(f'WARNING: Error in processing {day} data. Raw file saved to CSV instead.' )\n",
    "            except:\n",
    "                print(f'WARNING: Error in processing {day} data. FILE LOST.')\n",
    "                continue\n",
    "            continue\n",
    "    except:\n",
    "        print(f'Invalid URL for {day} - Date may be invalid or file may not exist.')\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wsu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
